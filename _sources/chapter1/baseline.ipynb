{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44b6f3ea",
   "metadata": {},
   "source": [
    "(chapter1_part2)=\n",
    "\n",
    "# Baseline\n",
    "\n",
    "Before we dive in some models, let's define heuristic that must be beaten. It is not just the case for RecSys\n",
    "problem, but in all ML projects you better start with a definition of baseline to understand efficiency of your model.\n",
    "Sometimes it is the case that some heuristice-based algorithm will do the work and it is ok -- the goal is your\n",
    "users and business value and the having exceptional ML model is not the goal at all.\n",
    "\n",
    "There are various ways to generate baseline recommendations. One of them is to recommend popular items\n",
    "based on some metrics like rating, counters (watch times, number of purchases, clicks etc.). Also,\n",
    "we can use groupping based on user segments to make more accurate and relevant recommendations (to some extent, of course :)).\n",
    "Here, we wil use mean rating as a proxy for popularity and recommendations\n",
    "\n",
    "In this chapter, I will walk through baseline recommender using [MovieLens Data](https://www.kaggle.com/code/quangnhatbui/movie-recommender/data)\n",
    "For convenience, I uploaded it to Google Drive for centralized access for anyone. Below, there are urls of main datasets that will be used\n",
    "for baseline recommender.\n",
    "\n",
    "\n",
    "## 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d16a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# links to shared data MovieLens\n",
    "RATINGS_SMALL_URL = 'http://drive.google.com/file/d/1BlZfCLLs5A13tbNSJZ1GPkHLWQOnPlE4/view?usp=share_link'\n",
    "MOVIES_METADATA_URL = 'http://drive.google.com/file/d/19g6-apYbZb5D-wRj4L7aYKhxS-fDM4Fb/view?usp=share_link'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e63fc44",
   "metadata": {},
   "source": [
    "## 1. Modules and functions\n",
    "Now, let's import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb1935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to make it available to download w/o SSL verification\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import islice, cycle, product\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9994e5",
   "metadata": {},
   "source": [
    " and define 2 useful functinons 1) read_csv_from_gdrive() to get data from provided url of a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_from_gdrive(url):\n",
    "    \"\"\"\n",
    "    gets csv data from a given url (taken from file -> share -> copy link)\n",
    "    :url: example https://drive.google.com/file/d/1BlZfCLLs5A13tbNSJZ1GPkHLWQOnPlE4/view?usp=share_link\n",
    "    \"\"\"\n",
    "    file_id = url.split('/')[-2]\n",
    "    file_path = 'https://drive.google.com/uc?export=download&id=' + file_id\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aea36b",
   "metadata": {},
   "source": [
    "2nd one is compute_popularity() which calculates mean rating, sorts and returns top *K* required items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e37c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_popularity(df: pd.DataFrame, item_id: str, max_candidates: int):\n",
    "    \"\"\"\n",
    "    calculates mean rating to define popular titles\n",
    "    \"\"\"\n",
    "    popular_titles = df.groupby(item_id).agg({'rating': np.mean})\\\n",
    "                     .sort_values(['rating'], ascending=False).head(max_candidates).index.values\n",
    "\n",
    "    return popular_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975e2110",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "### 2.1 Load and Describe\n",
    "\n",
    "Here, we will use two datasets:\n",
    "- interactions -- refers to `RATINGS_SMALL_URL` where we have userId, movieId, timestamp and rating (our so-called target)\n",
    "- movies_metadata -- refers to `MOVIES_METADATA_URL` where we have data all about movies - overview, genres etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50078ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactions data\n",
    "interactions = read_csv_from_gdrive(RATINGS_SMALL_URL)\n",
    "interactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd479709",
   "metadata": {},
   "source": [
    "Let's get some statistics and look at ratings' distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ed442",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217dbcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "interactions['rating'].hist();\n",
    "plt.title('Ratings Distribtion');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b822848",
   "metadata": {},
   "source": [
    "We see that in most cases we have 4 or 5 rating - right tail is fatter.\n",
    "Now, let's move on to movies metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ced50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# information about films etc\n",
    "movies_metadata = read_csv_from_gdrive(MOVIES_METADATA_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eef68bb",
   "metadata": {},
   "source": [
    "Which columns / info we have and their types - namings are pretty straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_metadata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0bbb51",
   "metadata": {},
   "source": [
    "### 2.2. Data Preparation\n",
    "Here, we will\n",
    "- preprocess column names;\n",
    "- set similar typing;\n",
    "- leave movies in `interactions` that are present in `movies_metadata`;\n",
    "- create users dataset for recommendatinos;\n",
    "- movies name and movie mapper for convenience\n",
    "\n",
    "First, we need to merge two dataframes and for that it is necessary to make appropiate typing and column name for convenience.\n",
    "Relationship between both datasets is set by movie id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ca51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# align data in both dataframes to merge\n",
    "interactions['movieId'] = interactions['movieId'].astype(str)\n",
    "movies_metadata.rename(columns = {'id': 'movieId'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27416bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave only those films that intersect with each other\n",
    "interactions_filtered = interactions.loc[interactions['movieId'].isin(movies_metadata['movieId'])]\n",
    "print(interactions.shape, interactions_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create users input\n",
    "users = interactions[['userId']].drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92459aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapper for movieId and title names\n",
    "item_name_mapper = dict(zip(movies_metadata['movieId'], movies_metadata['original_title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd3422d",
   "metadata": {},
   "source": [
    "## 3. Model\n",
    "Let's define our baseline popularity recommender BaselineRecommender - top rated titles based on average rating with possibility to get by any group(s)\n",
    "\n",
    "The pipeline will be similar to most python ML modules -- it will have two methods in the end: fit() and recommend()\n",
    "\n",
    "The logic of `fit()` as follow:\n",
    "- Initiate recommendation based on median rating from all observations recomm_common;\n",
    "- Prepare list of interacted items by users\n",
    "- If we set groups - we get recommendations i.e. calculate movie ratings by groups:\n",
    "    - If we get NaN, we fill with base recommendations \n",
    "    - If we get less than required number of candidates, we populate from base recommendations\n",
    "\n",
    "The logic of `recommend()`:\n",
    "- Return base recommendations if users data is not set;\n",
    "- In case of category wise requirement -- we get results of our fit\n",
    "\n",
    "### 3.1. Fit\n",
    "First, we define how many candidates we want to get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b0b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CANDIDATES = 20\n",
    "ITEM_COLUMN = 'movieId'\n",
    "USER_COLUMN = 'userId'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d084a",
   "metadata": {},
   "source": [
    "Then, we extract top 20 movies by aggregating movies and averaging rating column across all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3851741",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_recommendations = compute_popularity(interactions_filtered, ITEM_COLUMN, MAX_CANDIDATES)\n",
    "base_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5c9bf2",
   "metadata": {},
   "source": [
    "Thus, we got 20 films with highest average rating\n",
    "Now, as we discussed earlier, in movies recommendations there is no need to recommend the same film which user has already watched. Let's implement it as well\n",
    "We get all interacted items for each user and save it in dictionary {'userId': [items list]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e87340",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_items = interactions_filtered.groupby(USER_COLUMN)[ITEM_COLUMN].apply(list).to_dict()\n",
    "print(f\"Number of users with known items: {len(known_items)} \\n\")\n",
    "\n",
    "# let's check it for one userId = 1\n",
    "print(f\"Example of known item ids for particaular user: {known_items[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0467abf",
   "metadata": {},
   "source": [
    "Now we have all necessary components: base recommendations without groups with possibility to filter already watched items\n",
    "Also, if we want to get recommendations based on some user groups we can easily do the same with groupby() method and same approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add artifical binary group to check BaselineRecommender\n",
    "group = [np.random.random_integers(2) for x in range(len(users))]\n",
    "users['group'] = group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4fa2ff",
   "metadata": {},
   "source": [
    "Here we merge it to get groupwise recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34e9b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(interactions_filtered, users, how='left', on = USER_COLUMN)\n",
    "group_recommendations = data.groupby('group').apply(compute_popularity, ITEM_COLUMN, MAX_CANDIDATES)\n",
    "group_recommendations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9208dae",
   "metadata": {},
   "source": [
    "In the output we have two rows with a list of film ids for each binary group \n",
    "Next, we have to implement `recommned()` method which will use \n",
    "\n",
    "\n",
    "### 3.2. Recommend\n",
    "Earlier, we discussed that we can take just average / median etc. of rating and use it as popularity metric to use as recommendations.\n",
    "Thus, if we do not have groups to consider (a.k.a more granualar estimation), then it means we give the same recommendations\n",
    "for all users i.e. *base_recommendations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0527ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = list(islice(cycle([base_recommendations]), len(users['userId'])))\n",
    "users['rekkos'] = recs\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52edb8d",
   "metadata": {},
   "source": [
    "And let's have an example with groups we created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7003ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_recommendations = group_recommendations.reset_index()\n",
    "group_rekkos = pd.merge(users, group_recommendations, how = 'left', on = 'group')\n",
    "group_rekkos.rename(columns = {0: 'group_wise_rekkos'}, inplace = True)\n",
    "group_rekkos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9fb6a9",
   "metadata": {},
   "source": [
    "We got our groupwise recommendations from 3.1. part and just joined them by group of users are assigned to\n",
    "Further, we will prettify our code and wrap it into functions\n",
    "\n",
    "### 3.3. Wrap everything into pretty functions\n",
    "#### 3.3.1. Fit Part\n",
    "\n",
    "In this function, we need to support 4 main parameters\n",
    "- data -- it is going to be pandas classic DataFrame;\n",
    "- item_col -- name of the item id column so we can apply on any dataset;\n",
    "- groups -- if we need groupwise recommendations;\n",
    "- max_candidates -- number of recommendations to return\n",
    "\n",
    "Thus, our function will get pandas data frame with necessary data, calculate popularity for a given type -\n",
    "groupwise or not and return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fdf6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "    data: pd.DataFrame,\n",
    "    item_col: str,\n",
    "    groups: list = None,\n",
    "    max_candidates: int = 20\n",
    "    ):\n",
    "    \"\"\"\n",
    "    function runs all pipeline to generate recommendations based on given group\n",
    "    :data: dataframe of interactions\n",
    "    :item_col: item column name\n",
    "    :groups: optional, list of groups column names to get recommendations\n",
    "    :max_candidates: number of recommendations to return\n",
    "    \"\"\"\n",
    "    \n",
    "    if groups is not None:\n",
    "        recommendations = data.groupby(groups).apply(compute_popularity, item_col, max_candidates)\n",
    "    else:\n",
    "        recommendations = compute_popularity(data, item_col, max_candidates)\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f15b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check base recommendations\n",
    "fit(data, item_col=ITEM_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a9b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check group-wise\n",
    "fit(data, item_col=ITEM_COLUMN, groups=['group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f490432",
   "metadata": {},
   "source": [
    "#### 3.3.2. Recommend Part\n",
    "Here, we just use calculated recommendations from above method `fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a64030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(\n",
    "    users: pd.DataFrame,\n",
    "    recommendations: pd.DataFrame,\n",
    "    groups: list = None,\n",
    "    K: int = 10\n",
    "    ):\n",
    "    \"\"\"\n",
    "    recommends items for a given list of users\n",
    "    :users: series / list of users to recommend\n",
    "    :recommendations: output of fit() function\n",
    "    :groups: optional, list of groups column names to get recommendations\n",
    "    :K: number of items to recommend (not always we want to show dozens of items instantly)\n",
    "    \"\"\"\n",
    "    if groups is not None:\n",
    "        output = pd.merge(users, recommendations.reset_index(), how = 'left', on = 'group')\n",
    "\n",
    "    else:\n",
    "        output = users.copy(deep = True)\n",
    "        recs = list(islice(cycle([recommendations]), len(users['userId'])))\n",
    "        output['rekkos'] = recs\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76adaf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check base recommendations\n",
    "recs = fit(data, item_col=ITEM_COLUMN)\n",
    "check_recs = recommend(users[['userId', 'group']], recs)\n",
    "check_recs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55dcdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check group-wise\n",
    "recs = fit(data, item_col=ITEM_COLUMN, groups = ['group'])\n",
    "check_recs = recommend(users[['userId', 'group']], recs, ['group'])\n",
    "check_recs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7b23c9",
   "metadata": {},
   "source": [
    "Congrats! Your first basic recommender system is ready!!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   11,
   33,
   37,
   41,
   56,
   60,
   71,
   75,
   84,
   93,
   97,
   100,
   104,
   109,
   114,
   117,
   121,
   123,
   136,
   142,
   148,
   153,
   156,
   176,
   180,
   182,
   185,
   190,
   196,
   200,
   204,
   206,
   210,
   221,
   225,
   228,
   233,
   249,
   272,
   277,
   280,
   286,
   312,
   319,
   324
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}